{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b168193",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23a5f1ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f92c6c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# through \"os\" we are accessing the system's file and through getenv we are accessing api keys \n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n",
    "# we use this to access the new api key if anything is change in anycase keeping it updaated "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148bddbc",
   "metadata": {},
   "source": [
    "### Example 1 : simple llm call with streaming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ecedb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model # help to creat chat model\n",
    "from langchain_core.messages import HumanMessage, SystemMessage # helps to send message to llm and llm to human ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec1a03cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001DF56C209E0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001DF56C214F0>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialization of llm model\n",
    "model = init_chat_model(\"groq:llama-3.1-8b-instant\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e56c8081",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Another way of initialization of the model \n",
    "# from langchain_groq import ChatGroq\n",
    "# llm = ChatGroq(\"groq:llama-3.1-8b-instant\")\n",
    "# llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49e258bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create messages\n",
    "messages=[\n",
    "    SystemMessage(\"You are a helpfull AI Assistant\"),\n",
    "    HumanMessage(\"What are the top 2 Benifits of using Langchain?\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff8e0b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"LangChain is an open-source artificial intelligence (AI) framework that enables developers to build complex AI applications by integrating multiple AI models and tools. Two of the top benefits of using LangChain are:\\n\\n1. **Improved AI Model Integration**: LangChain provides a modular and flexible architecture that allows developers to integrate multiple AI models, such as language models, vision models, and data models, into a single application. This enables the creation of more sophisticated and accurate AI systems that can handle complex tasks and multimodal data.\\n\\n2. **Enhanced AI Development Efficiency**: LangChain's modular design and pre-built tools simplify the process of developing AI applications, reducing the time and effort required to build and deploy AI models. This is achieved through its features such as model chaining, data loading, and execution, which streamline the development process and enable developers to focus on building more complex and innovative AI applications.\\n\\nThese benefits contribute to faster development, increased accuracy, and more efficient use of AI capabilities, ultimately leading to improved outcomes in various industries and applications.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 207, 'prompt_tokens': 56, 'total_tokens': 263, 'completion_time': 0.354873744, 'prompt_time': 0.28725245, 'queue_time': 0.050969509, 'total_time': 0.642126194}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_46fc01befd', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--5b672af1-bacb-4e4c-b781-efaa0ac71519-0', usage_metadata={'input_tokens': 56, 'output_tokens': 207, 'total_tokens': 263})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#invoke the model\n",
    "response = model.invoke(messages)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is an open-source artificial intelligence (AI) framework that enables developers to build complex AI applications by integrating multiple AI models and tools. Two of the top benefits of using LangChain are:\n",
      "\n",
      "1. **Improved AI Model Integration**: LangChain provides a modular and flexible architecture that allows developers to integrate multiple AI models, such as language models, vision models, and data models, into a single application. This enables the creation of more sophisticated and accurate AI systems that can handle complex tasks and multimodal data.\n",
      "\n",
      "2. **Enhanced AI Development Efficiency**: LangChain's modular design and pre-built tools simplify the process of developing AI applications, reducing the time and effort required to build and deploy AI models. This is achieved through its features such as model chaining, data loading, and execution, which streamline the development process and enable developers to focus on building more complex and innovative AI applications.\n",
      "\n",
      "These benefits contribute to faster development, increased accuracy, and more efficient use of AI capabilities, ultimately leading to improved outcomes in various industries and applications.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "529b8060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"**Machine Learning: An Overview**\\n\\nMachine learning (ML) is a subset of artificial intelligence (AI) that involves training algorithms to learn from data, enabling them to make predictions, classify objects, or make decisions without being explicitly programmed.\\n\\n**Key Concepts:**\\n\\n1. **Training Data**: A dataset used to train the ML algorithm, which learns patterns and relationships within the data.\\n2. **Model**: The mathematical representation of the ML algorithm, which is trained on the training data.\\n3. **Prediction**: The output generated by the trained model, based on new, unseen data.\\n4. **Supervised Learning**: Training the model on labeled data, where the correct output is provided for each input.\\n5. **Unsupervised Learning**: Training the model on unlabeled data, where the goal is to identify patterns or relationships.\\n6. **Reinforcement Learning**: Training the model through trial and error, where the goal is to maximize a reward or minimize a penalty.\\n\\n**Types of Machine Learning:**\\n\\n1. **Supervised Learning**:\\n\\t* Classification (e.g., spam vs. non-spam emails)\\n\\t* Regression (e.g., predicting house prices)\\n2. **Unsupervised Learning**:\\n\\t* Clustering (e.g., grouping similar customers)\\n\\t* Dimensionality Reduction (e.g., reducing the number of features in a dataset)\\n3. **Reinforcement Learning**:\\n\\t* Game playing (e.g., AlphaGo)\\n\\t* Robotics (e.g., learning to navigate a maze)\\n\\n**Applications of Machine Learning:**\\n\\n1. **Image Classification**: Recognizing objects in images (e.g., facial recognition, image tagging)\\n2. **Natural Language Processing**: Understanding and generating human language (e.g., chatbots, language translation)\\n3. **Predictive Maintenance**: Predicting equipment failures or maintenance needs\\n4. **Customer Segmentation**: Identifying groups of customers with similar characteristics\\n\\n**Machine Learning Techniques:**\\n\\n1. **Linear Regression**: Predicting a continuous output variable\\n2. **Decision Trees**: Classifying data based on a tree-like structure\\n3. **Neural Networks**: Modeling complex relationships between inputs and outputs\\n4. **Support Vector Machines**: Classifying data using a high-dimensional space\\n\\n**Machine Learning Tools and Libraries:**\\n\\n1. **Python**: Popular language for ML development, with libraries like NumPy, pandas, and scikit-learn\\n2. **TensorFlow**: Google's open-source ML library, with a wide range of applications\\n3. **PyTorch**: Facebook's open-source ML library, with a focus on rapid prototyping\\n\\n**Challenges and Limitations:**\\n\\n1. **Data Quality**: High-quality data is essential for accurate ML models\\n2. **Overfitting**: Models may become too specialized to the training data\\n3. **Bias**: Models may perpetuate existing biases in the data\\n\\n**Conclusion:**\\n\\nMachine learning is a powerful tool for automating decision-making, predicting outcomes, and identifying patterns in data. While there are challenges and limitations, the potential benefits of ML are vast and continue to grow as the field advances.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 636, 'prompt_tokens': 39, 'total_tokens': 675, 'completion_time': 0.913460723, 'prompt_time': 0.007683591, 'queue_time': 0.059654229, 'total_time': 0.921144314}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_46fc01befd', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--419ce99c-5aec-42cd-b52e-c43f66e85cf9-0', usage_metadata={'input_tokens': 39, 'output_tokens': 636, 'total_tokens': 675})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([HumanMessage(\"what is machine learning\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langchain is an AI development platform that allows users to build and deploy conversational AI models. Based on my knowledge, the top 2 benefits of using Langchain are:\n",
      "\n",
      "1. **Effortless Conversational AI Development**: Langchain provides a user-friendly interface and a set of pre-built tools that enable developers to quickly create and deploy conversational AI models. This makes it easier to build sophisticated conversational interfaces without requiring extensive expertise in natural language processing (NLP) or machine learning.\n",
      "\n",
      "2. **Integration with LLMs (Large Language Models)**: Langchain provides seamless integration with popular LLMs such as Llama and other models, which are the foundation of conversational AI. By leveraging these powerful language models, developers can create highly accurate and engaging conversational interfaces that can understand and respond to user queries in a more human-like way.\n",
      "\n",
      "These benefits make Langchain an attractive choice for developers and organizations looking to build conversational AI applications, such as chatbots, virtual assistants, or language translation services."
     ]
    }
   ],
   "source": [
    "# Streaming of data from llm into chunks\n",
    "for chunk in model.stream(messages):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7676bacb",
   "metadata": {},
   "source": [
    "####Dynamic Prompt Templates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bec796",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
